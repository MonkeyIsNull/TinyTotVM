# IR (Intermediate Representation) Architecture

TinyTotVM includes an experimental register-based execution mode that translates stack-based bytecode to register-based Intermediate Representation (IR). This document describes the IR system architecture and capabilities.

## Overview

The IR system answers the fundamental question: **"Can concurrency operations be compiled to register form?"** - The answer is **YES**. The IR system successfully translates all TinyTotVM operations, including complex concurrency primitives, to register-based instructions.

## Key Components

### Stack-to-Register Translation (`src/ir/lowering.rs`)

The lowering pass converts stack-based bytecode to register-based IR:

- **Virtual Stack Simulation**: Maintains a virtual stack using registers
- **Register Allocation**: Efficiently assigns registers for operands and results
- **Full Instruction Coverage**: Translates all TinyTotVM operations including:
  - Arithmetic and logical operations
  - Control flow (jumps, conditionals)
  - Function calls and returns
  - Concurrency operations (SPAWN, SEND, RECEIVE, YIELD)
  - Variable operations (STORE, LOAD, DELETE)
  - I/O and system operations

### Register-Based VM (`src/ir/vm.rs`)

The RegisterVM executes register-based IR instructions:

- **Register File**: Array of Value registers for operand storage
- **Variable Management**: Hash map for named variable storage
- **Instruction Pointer**: Program counter for instruction execution
- **Concurrency Support**: Message handling and yielding capabilities

### IR Instruction Set (`src/ir/mod.rs`)

Comprehensive register-based instruction set including:

```rust
pub enum RegInstr {
    // Arithmetic operations
    Add(RegId, RegId, RegId),        // dst = src1 + src2
    Sub(RegId, RegId, RegId),        // dst = src1 - src2
    Mul(RegId, RegId, RegId),        // dst = src1 * src2
    Div(RegId, RegId, RegId),        // dst = src1 / src2
    
    // Concurrency operations  
    Spawn(RegId, RegId),             // dst_pid = spawn(function)
    Send(RegId, RegId),              // send(target_pid, message)
    Receive(RegId),                  // dst = receive()
    Yield,                           // yield to scheduler
    
    // Control flow
    Jmp(usize),                      // jump to address
    Jz(RegId, usize),               // jump if register is zero
    
    // Memory operations
    Mov(RegId, RegValue),           // move value to register
    Load(RegId, String),            // load variable to register
    Store(String, RegId),           // store register to variable
    
    // ... and 80+ more instructions
}
```

## Translation Process

### 1. Stack Analysis

The lowering pass analyzes stack-based operations:

```assembly
PUSH_INT 42        # Stack: [42]
PUSH_INT 10        # Stack: [42, 10]  
ADD                # Stack: [52]
PRINT              # Stack: []
```

### 2. Register Allocation

Converts to register operations:

```rust
// Translated IR:
Mov(r0, Const(Int(42)))     // r0 = 42
Mov(r1, Const(Int(10)))     // r1 = 10  
Add(r2, r0, r1)             // r2 = r0 + r1
Print(r2)                   // print r2
```

### 3. Concurrency Translation

Complex concurrency operations are successfully translated:

```assembly
# Stack-based
PUSH_STR "hello_world"
SPAWN                       # Creates process, returns PID
STORE worker_pid           # Store PID in variable

# Translated to IR
Mov(r0, Const(Str("hello_world")))  # r0 = "hello_world"
Spawn(r1, r0)                       # r1 = spawn(r0)
Store("worker_pid", r1)             # worker_pid = r1
```

## Concurrency Compilation Proof

The IR system demonstrates that **all concurrency operations can be compiled to register form**:

### SPAWN Operation
```rust
// Stack-based: SPAWN (pops function, pushes PID)
OpCode::Spawn => {
    let function = self.stack.pop()?;
    let dst_pid = self.block.alloc_register();
    self.block.add_instruction(RegInstr::Spawn(dst_pid, function));
    self.stack.push(dst_pid);
}
```

### SEND Operation  
```rust
// Stack-based: SEND target_pid (pops message)
OpCode::Send(target_pid) => {
    let message = self.stack.pop()?;
    let pid_reg = self.block.alloc_register();
    self.block.add_instruction(RegInstr::Mov(pid_reg, Const(Int(target_pid))));
    self.block.add_instruction(RegInstr::Send(pid_reg, message));
}
```

### RECEIVE Operation
```rust
// Stack-based: RECEIVE (pushes received message)
OpCode::Receive => {
    let dst = self.block.alloc_register();
    self.block.add_instruction(RegInstr::Receive(dst));
    self.stack.push(dst);
}
```

## Execution Modes

### Pure IR Mode (Simple Programs)
For programs without concurrency:
```bash
ttvm --use-ir examples/arithmetic.ttvm
```
- Direct RegisterVM execution
- Full register-based operations
- Optimal for computational tasks

### Hybrid Mode (Concurrent Programs)  
For programs with concurrency operations:
```bash
ttvm --use-ir examples/coffee_shop_demo.ttvm
```
- IR translation performed (proves compilation feasibility)
- TinyProc execution for full concurrency support
- Complete actor model functionality

## IR Instruction Examples

### Arithmetic Operations
```rust
// 5 + 3 * 2
Mov(r0, Const(Int(5)))      // r0 = 5
Mov(r1, Const(Int(3)))      // r1 = 3  
Mov(r2, Const(Int(2)))      // r2 = 2
Mul(r3, r1, r2)             // r3 = r1 * r2 (6)
Add(r4, r0, r3)             // r4 = r0 + r3 (11)
```

### Control Flow
```rust
// if (x > 0) goto positive
Mov(r0, Const(Int(0)))      // r0 = 0
Gt(r1, r_x, r0)             // r1 = (r_x > r0)
Jz(r1, positive_label)      // jump if r1 != 0
```

### Variable Operations
```rust
// x = y + z
Load(r0, "y")               // r0 = variable y
Load(r1, "z")               // r1 = variable z
Add(r2, r0, r1)             // r2 = r0 + r1
Store("x", r2)              // variable x = r2
```

## Research Applications

The IR system provides a foundation for:

### Compiler Optimization Research
- **Register Allocation**: Study optimal register assignment strategies
- **Dead Code Elimination**: Remove unused register operations
- **Constant Propagation**: Optimize constant values in registers
- **Loop Optimization**: Optimize register usage in loops

### Concurrency Research
- **Register-Based Actors**: Study register-based actor model implementation
- **Message Passing Optimization**: Optimize inter-process communication
- **Scheduler Integration**: Research register-based process scheduling
- **Memory Models**: Study register-based memory consistency

### Performance Analysis
- **Instruction Counting**: Precise operation counting in register form
- **Memory Access Patterns**: Analyze register vs. memory operations
- **Branch Prediction**: Study control flow in register-based code
- **Cache Behavior**: Analyze register file vs. stack cache usage

## Implementation Status

### âœ… Completed Features
- **Full IR Translation**: All TinyTotVM operations translate to register form
- **Register Allocation**: Efficient virtual register management
- **Virtual Stack**: Complete stack simulation using registers
- **Concurrency Compilation**: Proof that concurrency operations can be register-based
- **Standalone Execution**: Pure IR execution for simple programs
- **Hybrid Execution**: IR translation with TinyProc execution for concurrency

### ðŸ”¬ Research Opportunities
- **Native IR Scheduler**: Full register-based concurrency execution
- **Register Optimization**: Advanced register allocation algorithms
- **IR-to-Native**: Compile IR to native machine code
- **JIT Compilation**: Just-in-time compilation of hot IR regions
- **Parallel IR**: Multi-threaded register-based execution

## Usage Examples

### Basic IR Execution
```bash
# Simple arithmetic - pure IR execution
ttvm --use-ir examples/math_test.ttvm

# Output shows register-based execution
```

### Concurrency IR Translation
```bash
# Concurrent program - IR translation + TinyProc execution  
ttvm --use-ir examples/coffee_shop_demo.ttvm

# Output shows:
# "Note: IR translation performed, but using TinyProc execution for full concurrency support"
```

### IR Translation Verification
```bash
# Any program can be translated to IR
ttvm --use-ir any_program.ttvm

# IR lowering pass always succeeds, proving compilation feasibility
```

## Technical Insights

### Stack vs Register Paradigms
- **Stack-based**: Simple, compact bytecode, complex execution
- **Register-based**: Complex bytecode, optimized execution, better for optimization

### Translation Complexity
- **Simple Operations**: Direct 1:1 mapping (ADD â†’ Add)
- **Stack Manipulation**: Requires virtual stack simulation (DUP, SWAP)
- **Control Flow**: Address translation and register-based conditions
- **Concurrency**: Message handling and process lifecycle management

### Performance Characteristics
- **Fewer Instructions**: Register operations often require fewer instructions
- **Explicit Dependencies**: Register form makes data dependencies explicit
- **Optimization Friendly**: Register form enables advanced compiler optimizations
- **Memory Efficiency**: Reduces stack manipulation overhead

## Conclusion

The IR system definitively proves that **concurrency operations can be compiled to register form**. While the current implementation uses hybrid execution for practical concurrency support, the successful IR translation demonstrates the feasibility of fully register-based concurrent execution.

This foundation enables future research into register-based actor models, optimized message passing, and high-performance concurrent virtual machines.